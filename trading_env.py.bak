import numpy as np
import pandas as pd
from gymnasium import Env
from gymnasium.spaces import Discrete, Box, Dict, Tuple
from collections import OrderedDict
import gymnasium
import os
import datetime
from pathlib import Path
import sys

class TradingEnv(Env):
    def __init__(self, df, debug=False, max_steps=None, model_name=None, input_dir_name=None, test_mode=False, stoploss=False, stoploss_min=0.01, stoploss_max=1.0):
        super().__init__()
        
        self.total_reward = 0
        
        self.stoploss = stoploss
        self.stoploss_min = stoploss_min
        self.stoploss_max = stoploss_max
        self.stoploss_price = None
        self.stoploss_distance = None
        
        # Define action and observation space first (required by gym.Env)
        # Action space: 0=HOLD, 1=BUY, 2=SELL (default)
        if self.stoploss:
            self.action_space = gymnasium.spaces.Tuple([
                Discrete(3),
                Box(low=np.array([self.stoploss_min], dtype=np.float32), high=np.array([self.stoploss_max], dtype=np.float32), shape=(1,), dtype=np.float32)
            ])
        else:
            self.action_space = Discrete(3)
        
        # Observation space: 13 features
        # 1. Normalized OHLCV (5 features)
        # 2. Position info (4 features: shares, balance, net_worth, position_open)
        # 3. Time features (4 features: normalized_time, is_pre_market, is_after_hours, normalized_time_until_close)
        
        # Define observation space with reasonable bounds for each feature
        self.observation_space = Dict({
            'obs': Box(
                low=np.array([
                    -10.0, -10.0, -10.0, -10.0,  # Normalized OHLC
                    -10.0,  # Normalized volume
                    -1.0,   # Normalized shares
                    -1.0,   # Normalized balance
                    -10.0,  # Normalized net worth
                    0.0,    # Position open (binary)
                    0.0,    # Normalized time
                    0.0,    # is_pre_market (binary)
                    0.0,    # is_after_hours (binary)
                    -1.0    # Normalized time until close
                ]),
                high=np.array([
                    10.0, 10.0, 10.0, 10.0,  # Normalized OHLC
                    10.0,  # Normalized volume
                    1.0,   # Normalized shares
                    10.0,  # Normalized balance
                    10.0,  # Normalized net worth
                    1.0,   # Position open (binary)
                    1.0,   # Normalized time
                    1.0,   # is_pre_market (binary)
                    1.0,   # is_after_hours (binary)
                    1.0    # Normalized time until close
                ]),
                dtype=np.float32
            ),
            'action_mask': Box(0, 1, shape=(3,), dtype=np.int8)  # 3 actions: HOLD, BUY, SELL
        })
        
        # Handle df=None for env checkers or dummy instantiation
        self.df = df
        # Restore market open/close time attributes for time feature calculations
        self.market_open = pd.Timestamp('04:00:00').time()  # 4:00 AM
        self.market_close = pd.Timestamp('20:00:00').time()  # 8:00 PM
        if df is not None:
            # If datetime is the index, reset it to be a column
            if 'datetime' not in df.columns:
                df = df.reset_index()
                df.rename(columns={'Date': 'datetime'}, inplace=True)
            self.df = df
            self.max_steps = max_steps if max_steps is not None else len(df) - 1
        else:
            self.max_steps = max_steps if max_steps is not None else 1000  # fallback
        self.current_step = 0
        self.initial_balance = 10000  # Starting cash
        self.balance = self.initial_balance
        self.net_worth = self.initial_balance
        self.max_net_worth = self.initial_balance
        self.shares = 0
        self.buy_price = 0
        self.buy_step = None
        self.position_open = False  # Track open positions
        self.round_trip_trades = 0  # Counter for buy-sell cycles
        self.debug = debug
        self.model_name = model_name
        self.input_dir_name = input_dir_name or 'default'
        self.test_mode = test_mode
        
        # Always use training_debut.txt in project root for debug logging
        self.debug_file = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'training_debut.txt')
        # Overwrite the debug file on every new environment initialization
        with open(self.debug_file, 'w') as f:
            timestamp = '2025-06-13 10:53:02'
            f.write(f"TradingEnv Debug Log - {timestamp}\n")
            if self.model_name:
                f.write(f"Model: {self.model_name}\n")
            f.write("=" * 40 + "\n\n")
            f.flush()

        # Preprocess time information
        if df is not None:
            self._preprocess_time()
            
        # Fail-safe print to confirm successful initialization
        print("[SAFE_PRINT] TradingEnv initialized successfully")
        print(f"[SAFE_PRINT] Debug logging to: {os.path.abspath(self.debug_file)}")

    def _debug_print(self, message):
        """Write debug message to training_debut.txt in project root."""
        # Skip market hours debug messages
        if 'Market day duration:' in message or 'Is pre-market:' in message or 'Is after-hours:' in message:
            return
        debug_message = message
        try:
            with open(self.debug_file, 'a') as f:
                f.write(f"{debug_message}\n")
                f.flush()
        except Exception as e:
            print(f"Error writing to training_debut.txt: {e}", file=sys.stderr)

    def _preprocess_time(self):
        """Calculate time-based features."""
        # Convert datetime column to proper datetime format
        # Handle two-digit years by assuming they are in the 2000s
        self.df['datetime'] = pd.to_datetime(self.df['datetime'], format='%m/%d/%y %H:%M', exact=False)
        # Set the year to 2025 explicitly
        self.df['datetime'] = self.df['datetime'].apply(lambda x: x.replace(year=2025))
        
        # Extract hour and minute from datetime
        self.df['hour'] = self.df['datetime'].dt.hour
        self.df['minute'] = self.df['datetime'].dt.minute
        
        # Calculate market session duration in minutes
        # Convert time objects to minutes since midnight
        market_open_minutes = self.market_open.hour * 60 + self.market_open.minute
        market_close_minutes = self.market_close.hour * 60 + self.market_close.minute
        market_minutes = market_close_minutes - market_open_minutes
        if self.debug:
            self._debug_print(f"\nMarket day duration: {market_minutes} minutes")

        # Calculate time since market open (in minutes)
        # Convert current time to minutes since midnight
        self.df['time_since_open'] = (self.df['hour'] * 60 + self.df['minute']) - market_open_minutes
        
        # Normalize time since open to [0, 1] using market hours
        self.df['normalized_time'] = self.df['time_since_open'] / market_minutes
        if self.debug:
            self._debug_print(f"Normalized time (first row): {self.df['normalized_time'].iloc[0]}")
        
        # Calculate time until market close (in minutes)
        # 7:59 PM is market close, so calculate time remaining
        # Ensure time_until_close is always non-negative
        self.df['time_until_close'] = np.maximum(0, ((self.market_close.hour * 60 + self.market_close.minute) - (self.df['hour'] * 60 + self.df['minute'])))
        self.df['normalized_time_until_close'] = self.df['time_until_close'] / market_minutes
        if self.debug:
            self._debug_print(f"Normalized time until close (first row): {self.df['normalized_time_until_close'].iloc[0]}")
        
        # Define session periods
        pre_market_end = 9.5  # 9:30 AM
        after_hours_start = 16  # 4:00 PM
        
        # Calculate is_pre_market
        self.df['is_pre_market'] = ((self.df['hour'] >= self.market_open.hour) & 
                                 (self.df['hour'] < 9.5) & 
                                 (self.df['minute'] < 30)).astype(float)
        
        # Calculate is_after_hours
        self.df['is_after_hours'] = ((self.df['hour'] >= 16) & 
                                   (self.df['hour'] < self.market_close.hour) & 
                                   (self.df['minute'] < 59)).astype(float)
        
        # Debug print for specific hours
        if self.debug:
            self._debug_print("\nDebug information for session periods:")
            self._debug_print("4:00 AM - Start of day:")
            self._debug_print(f"Is pre-market: {((4 >= 4) and (4 < 9.5) and (0 < 30))}")
            self._debug_print(f"Is after-hours: {((4 >= 16) and (4 < 19) and (0 < 59))}")
            
            self._debug_print("\n9:30 AM - End of pre-market:")
            self._debug_print(f"Is pre-market: {((9.5 >= 4) and (9.5 < 9.5) and (0 < 30))}")
            self._debug_print(f"Is after-hours: {((9.5 >= 16) and (9.5 < 19) and (0 < 59))}")
            
            self._debug_print("\n4:00 PM - Start of after-hours:")
            self._debug_print(f"Is pre-market: {((16 >= 4) and (16 < 9.5) and (0 < 30))}")
            self._debug_print(f"Is after-hours: {((16 >= 16) and (16 < 19) and (0 < 59))}")
            
            self._debug_print("\n7:59 PM - End of day:")
            self._debug_print(f"Is pre-market: {((19 >= 4) and (19 < 9.5) and (59 < 30))}")
            self._debug_print(f"Is after-hours: {((19 >= 16) and (19 < 19) and (59 < 59))}")

    def get_obs(self):
        # Get current row from the dataframe
        current_row = self.df.iloc[self.current_step]
        
        # Calculate time-based features
        current_time = pd.to_datetime(current_row['datetime']).time()
        
        # Calculate normalized time (0 to 1) within the trading day
        market_open_seconds = (self.market_open.hour * 3600 + 
                             self.market_open.minute * 60 + 
                             self.market_open.second)
        market_close_seconds = (self.market_close.hour * 3600 + 
                              self.market_close.minute * 60 + 
                              self.market_close.second)
        current_seconds = (current_time.hour * 3600 + 
                         current_time.minute * 60 + 
                         current_time.second)
        
        # Normalize time to [0, 1] range
        normalized_time = (current_seconds - market_open_seconds) / (market_close_seconds - market_open_seconds)
        
        # Time until market close (normalized to [0, 1])
        time_until_close = (market_close_seconds - current_seconds) / (market_close_seconds - market_open_seconds)
        
        # Time of day features
        is_pre_market = 1.0 if current_seconds < market_open_seconds else 0.0
        is_after_hours = 1.0 if current_seconds > market_close_seconds else 0.0
        
        # Normalize time until close to [-1, 1] range
        normalized_time_until_close = 2 * time_until_close - 1
        
        # Normalize price and volume data using running statistics
        price_mean = current_row[['open', 'high', 'low', 'close']].mean()
        price_std = current_row[['open', 'high', 'low', 'close']].std() + 1e-8  # Avoid division by zero
        normalized_prices = (current_row[['open', 'high', 'low', 'close']] - price_mean) / price_std
        
        # Normalize volume using log scale to handle large ranges
        normalized_volume = np.log1p(current_row['volume']) / 10.0  # Scale down
        
        # Normalize position and balance
        max_shares = 10000  # Reasonable upper limit
        max_balance = self.initial_balance * 10  # Allow up to 10x initial balance
        normalized_shares = self.shares / max_shares
        normalized_balance = self.balance / max_balance
        normalized_net_worth = self.net_worth / self.initial_balance  # Relative to initial
        
        # Create observation array with normalized values
        obs_array = np.array([
            normalized_prices['open'],
            normalized_prices['high'],
            normalized_prices['low'],
            normalized_prices['close'],
            normalized_volume,
            normalized_shares,
            normalized_balance,
            normalized_net_worth,
            float(self.position_open),
            normalized_time,
            is_pre_market,
            is_after_hours,
            normalized_time_until_close
        ], dtype=np.float32)
        
        # Clip values to prevent extreme outliers
        obs_array = np.clip(obs_array, -10.0, 10.0)
        
        # Get action mask (shape: (3,))
        action_mask = self.get_action_mask()
        
        # Return observation as a dictionary with the correct structure for RLlib
        return {
            'obs': obs_array,
            'action_mask': action_mask
        }

    def _calculate_reward(self, action, current_row):
        """Calculate reward for the given action.
        
        Rewards are structured to:
        - Encourage profitable trades
        - Discourage overtrading
        - Reward holding positions with good risk/reward
        """
        current_price = current_row['close']
        reward = 0.0
        
        # Calculate steps since last buy
        hold_steps = self.current_step - self.buy_step if self.position_open else 0
        
        # Unpack action if using stoploss
        if self.stoploss and isinstance(action, (tuple, list, np.ndarray)):
            action = int(action[0])  # Extract the discrete action
        
        action = int(action)  # Ensure action is an integer
        
        # Small time penalty to encourage faster convergence
        time_penalty = -0.01
        
        # HOLD action
        if action == 0:
            if self.position_open:
                # Calculate unrealized P&L
                pnl = (current_price - self.buy_price) / self.buy_price  # Percentage return
                
                # Small reward for holding profitable positions
                if pnl > 0:
                    reward = pnl * 0.1  # Scale down to avoid large updates
                else:
                    reward = pnl * 0.05  # Smaller penalty for holding losing positions
                    
                # Add time penalty
                reward += time_penalty
                
                if self.debug:
                    self._debug_print(f"[DEBUG_REWARD] HOLD - P&L: {pnl*100:.2f}%, Reward: {reward:.4f}")
            else:
                # Small penalty for holding cash (encourage taking positions)
                reward = -0.01
                if self.debug:
                    self._debug_print("[DEBUG_REWARD] HOLD (no position) - Reward: -0.01")
        
        # BUY action
        elif action == 1:
            if not self.position_open and self.balance >= current_price * 1000:
                # Small penalty for buying (to prevent overtrading)
                reward = -0.05
                if self.debug:
                    self._debug_print(f"[DEBUG_REWARD] BUY - Penalty: {reward:.4f}")
            else:
                # Invalid BUY action - should be masked
                reward = -0.1
                if self.debug:
                    self._debug_print(f"[DEBUG_REWARD] INVALID BUY - Penalty: {reward:.4f}")
        
        # SELL action
        elif action == 2:
            if self.position_open and self.shares > 0:
                # Calculate P&L for the trade
                pnl = (current_price - self.buy_price) / self.buy_price  # Percentage return
                
                # Scale reward based on P&L and hold time
                if pnl > 0:
                    # Reward profitable trades more
                    reward = pnl * 10  # Scale up to make it meaningful
                    
                    # Bonus for holding longer (up to 2x reward for holding 50+ steps)
                    hold_bonus = min(hold_steps / 50.0, 1.0)
                    reward *= (1.0 + hold_bonus)
                    
                    if self.debug:
                        self._debug_print(f"[DEBUG_REWARD] PROFITABLE SELL - P&L: {pnl*100:.2f}%, Hold steps: {hold_steps}, Reward: {reward:.4f}")
                else:
                    # Penalize losing trades less severely than missing profits
                    reward = pnl * 5
                    if self.debug:
                        self._debug_print(f"[DEBUG_REWARD] UNPROFITABLE SELL - P&L: {pnl*100:.2f}%, Hold steps: {hold_steps}, Reward: {reward:.4f}")
            else:
                # Invalid SELL action - should be masked
                reward = -0.1
                if self.debug:
                    self._debug_print(f"[DEBUG_REWARD] INVALID SELL - Penalty: {reward:.4f}")
        
        # Clip reward to reasonable range
        reward = np.clip(reward, -10.0, 10.0).item()
        self.total_reward += reward
        
        return reward

    def _update_state(self, action, current_row):
        """Update environment state based on the action taken. Supports stoploss logic."""
        prev_position_open = self.position_open
        prev_shares = self.shares

        if self.stoploss:
            if isinstance(action, (tuple, list, np.ndarray)) and len(action) == 2:
                action_type = int(action[0])
                stoploss_distance = float(action[1])
                stoploss_distance = np.clip(stoploss_distance, self.stoploss_min, self.stoploss_max)
            else:
                raise ValueError("Action must be (action_type, stoploss_distance) when stoploss is enabled.")
        else:
            action_type = int(action)
            stoploss_distance = None

        if action_type == 1:  # Buy
            if not self.position_open and self.balance >= current_row['close'] * 1000:
                self.shares = 1000
                self.balance -= current_row['close'] * 1000
                self.position_open = True
                self.buy_price = current_row['close']
                self.buy_step = self.current_step
                self.net_worth = self.balance + (self.shares * current_row['close'])
                self.max_net_worth = max(self.max_net_worth, self.net_worth)
                if self.stoploss:
                    self.stoploss_distance = stoploss_distance
                    # stoploss_distance is a percentage (e.g., 0.01 = 1%)
                    price_str = f"{self.buy_price:.10f}"
                    decimals = len(price_str.rstrip('0').split('.')[-1])
                    decimals = max(2, min(decimals, 3))  # Clamp to 2 or 3
                    self.stoploss_price = self.buy_price - (self.buy_price * self.stoploss_distance)
                    self.stoploss_price = round(self.stoploss_price, decimals)
                    if self.debug:
                        self._debug_print(f"[DEBUG_STOPLOSS] BUY: buy_price={self.buy_price}, stoploss_pct={self.stoploss_distance}, decimals={decimals}, stoploss_price={self.stoploss_price}")
                # Record successful buy signal
                if self.debug:
                    self._debug_print(f"[DEBUG] BUY executed at {current_row['datetime']} - "
                                     f"Price: {current_row['close']}, "
                                     f"Shares: {self.shares}, "
                                     f"Balance: {self.balance}, "
                                     f"Net Worth: {self.net_worth}, "
                                     f"Stoploss: {self.stoploss_price if self.stoploss else None}")
            elif self.debug:
                self._debug_print(f"[DEBUG] BUY failed - Position open: {self.position_open}, "
                                  f"Balance: {self.balance}, "
                                  f"Required: {current_row['close'] * 1000}")
        elif action_type == 2:  # Sell
            if self.position_open and self.shares > 0:
                sell_value = current_row['close'] * self.shares
                profit = sell_value - (self.buy_price * self.shares)
                self.balance += sell_value
                self.shares = 0
                self.position_open = False
                self.buy_price = 0
                self.buy_step = None
                self.net_worth = self.balance
                self.max_net_worth = max(self.max_net_worth, self.net_worth)
                if self.stoploss:
                    self.stoploss_price = None
                    self.stoploss_distance = None
                # Record successful sell signal
                if self.debug:
                    self._debug_print(f"[DEBUG] SELL executed at {current_row['datetime']} - "
                                     f"Price: {current_row['close']}, "
                                     f"Profit: {profit}, "
                                     f"Balance: {self.balance}, "
                                     f"Net Worth: {self.net_worth}")
            else:
                if self.debug:
                    self._debug_print(f"[DEBUG] SELL failed - Position open: {self.position_open}, "
                                      f"Shares: {self.shares}")
                if self.shares == 0:
                    self.buy_step = None
        else:  # Hold
            if self.position_open:
                self.net_worth = self.balance + (self.shares * current_row['close'])
                self.max_net_worth = max(self.max_net_worth, self.net_worth)
            else:
                self.net_worth = self.balance
                self.max_net_worth = max(self.max_net_worth, self.net_worth)

        # Validate state consistency
        if self.shares > 0:
            assert self.position_open, f"Shares > 0 but position_open=False (shares: {self.shares}, position_open: {self.position_open})"
            assert self.buy_price > 0, f"Shares > 0 but buy_price=0 (shares: {self.shares}, buy_price: {self.buy_price})"
            assert self.buy_step is not None, f"Shares > 0 but buy_step is None (shares: {self.shares}, buy_step: {self.buy_step})"
        else:
            assert not self.position_open, f"Shares == 0 but position_open=True (shares: {self.shares}, position_open: {self.position_open})"
            assert self.buy_price == 0, f"Shares == 0 but buy_price > 0 (shares: {self.shares}, buy_price: {self.buy_price})"
            assert self.buy_step is None, f"Shares == 0 but buy_step is not None (shares: {self.shares}, buy_step: {self.buy_step})"

        # Update action mask based on current state
        if hasattr(self.action_space, 'n'):
            n_actions = self.action_space.n
        else:
            n_actions = self.action_space[0].n
        action_mask = np.zeros(n_actions, dtype=bool)
        if not self.position_open:
            action_mask[0] = True  # Hold
            action_mask[1] = True  # Buy
        else:
            action_mask[0] = True  # Hold
            action_mask[2] = True  # Sell

        return action_mask

    def get_valid_actions(self):
        """Get valid actions based on current state."""
        valid_actions = [0]  # Hold is always valid
        if not self.position_open:  # Allow Buy only if no position is open
            valid_actions.append(1)
        if self.position_open:  # Allow Sell only if position is open
            valid_actions.append(2)
        return valid_actions

    def get_action_mask(self) -> np.ndarray:
        """
        Returns a binary mask indicating valid actions.
        True indicates a valid action, False indicates an invalid action.
        Handles both Discrete and Tuple action spaces.
        """
        if hasattr(self.action_space, 'n'):
            num_actions = self.action_space.n
        elif hasattr(self.action_space, 'spaces') and hasattr(self.action_space.spaces[0], 'n'):
            num_actions = self.action_space.spaces[0].n
        else:
            raise ValueError("Unsupported action space for action masking.")
        action_mask = np.zeros(num_actions, dtype=bool)
        for act in self.get_valid_actions():
            action_mask[act] = True
        return action_mask

    def action_masks(self) -> np.ndarray:
        """
        Returns a binary mask indicating valid actions.
        True indicates a valid action, False indicates an invalid action.
        """
        action_mask = np.zeros(self.action_space.n, dtype=bool)
        for act in self.get_valid_actions():
            action_mask[act] = True
        return action_mask

    def step(self, action):
        if self.df is None:
            raise ValueError("TradingEnv was initialized with df=None. Please provide a valid DataFrame before calling step().")
            
        # Get valid actions and action mask BEFORE processing the action
        valid_actions_before = self.get_valid_actions()
        action_mask_before = self.get_action_mask()
        
        # If stoploss is enabled, unpack action
        if self.stoploss:
            if isinstance(action, (tuple, list, np.ndarray)) and len(action) == 2:
                action_type = int(action[0])
                stoploss_distance = float(action[1])
                stoploss_distance = np.clip(stoploss_distance, self.stoploss_min, self.stoploss_max)
            elif isinstance(action, (int, np.integer)):
                # Handle case where action is just an integer (happens during testing)
                action_type = int(action)
                stoploss_distance = np.array([0.01], dtype=np.float32)  # Default stoploss
            else:
                raise ValueError(f"Invalid action format: {action}. Expected (action_type, stoploss_distance) or action_type.")
        else:
            action_type = int(action)
            stoploss_distance = None
            
        # Check if action is valid
        is_invalid = action_type not in valid_actions_before
        
        if is_invalid and self.debug:
            action_names = {0: 'HOLD', 1: 'BUY', 2: 'SELL'}
            self._debug_print(f"[WARNING] Invalid action {action_names.get(action_type, action_type)} "
                            f"taken when valid actions are {[action_names.get(a, a) for a in valid_actions_before]}")
            # Force a HOLD action if invalid
            action_type = 0
            stoploss_distance = None

        if self.debug:
            action_names = {0: 'HOLD', 1: 'BUY', 2: 'SELL'}
            self._debug_print(f"\n[STEP] Step {self.current_step}: Action {action_names.get(action_type, action_type)}" + (f", Stoploss {stoploss_distance}" if self.stoploss else ""))

        current_row = self.df.iloc[self.current_step]

        # Stoploss logic: if position open, check if stoploss hit
        stoploss_triggered = False
        if self.stoploss and self.position_open and self.stoploss_price is not None:
            if self.debug:
                self._debug_print(f"[DEBUG_STOPLOSS] Step {self.current_step}: Checking stoploss - current_low={current_row['low']}, stoploss_price={self.stoploss_price}")
            if current_row['low'] <= self.stoploss_price:
                # Stoploss triggered: close position at stoploss price
                stoploss_triggered = True
                sell_value = self.stoploss_price * self.shares
                self.balance += sell_value
                self.shares = 0
                self.position_open = False
                self.buy_price = 0
                self.buy_step = None
                self.net_worth = self.balance
                self.stoploss_price = None
                self.stoploss_distance = None
                if self.debug:
                    self._debug_print(f"[STOPLOSS] Triggered at {current_row['datetime']} - Forced SELL at stoploss_price={self.stoploss_price}")

        # If stoploss triggered, calculate reward as SELL at stoploss price
        if stoploss_triggered:
            # Create a dummy row with 'close' set to stoploss price for reward calculation
            stoploss_row = current_row.copy()
            stoploss_row['close'] = self.stoploss_price
            reward = self._calculate_reward(2, stoploss_row)  # 2 = SELL
            if self.debug:
                self._debug_print(f"[DEBUG_STOPLOSS] Reward for stoploss-triggered SELL: {reward}")
        else:
            if self.debug:
                self._debug_print(f"[DEBUG] BUY executed at {current_row['datetime']} - "
                                 f"Price: {current_row['close']}, "
                                 f"Shares: {self.shares}, "
                                 f"Balance: {self.balance}, "
                                 f"Net Worth: {self.net_worth}, "
                                 f"Stoploss: {self.stoploss_price if self.stoploss else None}")
        
        if action_type == 2:  # Sell
            if self.position_open and self.shares > 0:
                sell_value = current_row['close'] * self.shares
                profit = sell_value - (self.buy_price * self.shares)
                self.balance += sell_value
                self.shares = 0
                self.position_open = False
                self.buy_price = 0
                self.buy_step = None
                self.net_worth = self.balance
                self.max_net_worth = max(self.max_net_worth, self.net_worth)
                if self.stoploss:
                    self.stoploss_price = None
                    self.stoploss_distance = None
                # Record successful sell signal
                if self.debug:
                    self._debug_print(f"[DEBUG] SELL executed at {current_row['datetime']} - "
                                    f"Price: {current_row['close']}, "
                                    f"Profit: {profit}, "
                                    f"Balance: {self.balance}, "
                                    f"Net Worth: {self.net_worth}")
            else:
                if self.debug:
                    self._debug_print(f"[DEBUG] SELL failed - Position open: {self.position_open}, "
                                    f"Shares: {self.shares}")
                if self.shares == 0:
                    self.buy_step = None
        else:  # Hold
            if self.position_open:
                self.net_worth = self.balance + (self.shares * current_row['close'])
                self.max_net_worth = max(self.max_net_worth, self.net_worth)
            else:
                self.net_worth = self.balance
                self.max_net_worth = max(self.max_net_worth, self.net_worth)

        # Validate state consistency
        if self.shares > 0:
            assert self.position_open, f"Shares > 0 but position_open=False (shares: {self.shares}, position_open: {self.position_open})"
            assert self.buy_price > 0, f"Shares > 0 but buy_price=0 (shares: {self.shares}, buy_price: {self.buy_price})"
            assert self.buy_step is not None, f"Shares > 0 but buy_step is None (shares: {self.shares}, buy_step: {self.buy_step})"
        else:
            assert not self.position_open, f"Shares == 0 but position_open=True (shares: {self.shares}, position_open: {self.position_open})"
            assert self.buy_price == 0, f"Shares == 0 but buy_price > 0 (shares: {self.shares}, buy_price: {self.buy_price})"
            assert self.buy_step is None, f"Shares == 0 but buy_step is not None (shares: {self.shares}, buy_step: {self.buy_step})"

        # Update action mask based on current state
        if hasattr(self.action_space, 'n'):
            n_actions = self.action_space.n
        else:
            n_actions = self.action_space[0].n
        action_mask = np.zeros(n_actions, dtype=bool)
        if not self.position_open:
            action_mask[0] = True  # Hold
            action_mask[1] = True  # Buy
        else:
            action_mask[0] = True  # Hold
            action_mask[2] = True  # Sell

        return action_mask

    def get_valid_actions(self):
        """Get valid actions based on current state."""
        valid_actions = [0]  # Hold is always valid
        if not self.position_open:  # Allow Buy only if no position is open
            valid_actions.append(1)
        if self.position_open:  # Allow Sell only if position is open
            valid_actions.append(2)
        return valid_actions

    def get_action_mask(self) -> np.ndarray:
        """
        Returns a binary mask indicating valid actions.
        True indicates a valid action, False indicates an invalid action.
        Handles both Discrete and Tuple action spaces.
        """
        if hasattr(self.action_space, 'n'):
            num_actions = self.action_space.n
        elif hasattr(self.action_space, 'spaces') and hasattr(self.action_space.spaces[0], 'n'):
            num_actions = self.action_space.spaces[0].n
        else:
            raise ValueError("Unsupported action space for action masking.")
        action_mask = np.zeros(num_actions, dtype=bool)
        for act in self.get_valid_actions():
            action_mask[act] = True
        return action_mask

    def action_masks(self) -> np.ndarray:
        """
        Returns a binary mask indicating valid actions.
        True indicates a valid action, False indicates an invalid action.
        """
        action_mask = np.zeros(self.action_space.n, dtype=bool)
        for act in self.get_valid_actions():
            action_mask[act] = True
        return action_mask

    def step(self, action):
        """Take a step in the environment, supporting stoploss if enabled."""
        current_row = self.df.iloc[self.current_step]
        print(f"[DEBUG] current_row set at step {self.current_step}: {current_row.to_dict()}")

        # Unpack action
        if self.stoploss:
            if isinstance(action, (tuple, list, np.ndarray)) and len(action) == 2:
                action_type = int(action[0])
                stoploss_distance = float(action[1])
                stoploss_distance = np.clip(stoploss_distance, self.stoploss_min, self.stoploss_max)
            else:
                # Fallback if action is not a tuple (for backward compatibility)
                action_type = int(action)
                stoploss_distance = (self.stoploss_min + self.stoploss_max) / 2  # Default stoploss distance
                if self.debug:
                    self._debug_print(f"[WARNING] Expected tuple action with stoploss, got {action}. Using default stoploss: {stoploss_distance}")
        else:
            # Handle non-stoploss case (regular discrete actions)
            if isinstance(action, (tuple, list, np.ndarray)) and len(action) > 0:
                action_type = int(action[0])  # Use first element if action is a sequence
            else:
                action_type = int(action)  # Direct conversion if not a sequence
            stoploss_distance = None

        # Get valid actions and action mask BEFORE updating the state
        action_names = {0: 'HOLD', 1: 'BUY', 2: 'SELL'}
        valid_actions_before = self.get_valid_actions()
        action_mask_before = self.get_action_mask()

        # Log the action that will be executed
        if self.debug:
            try:
                if isinstance(action, (tuple, list, np.ndarray)):
                    action_key = int(action[0])
                elif hasattr(action, 'item'):
                    action_key = int(action.item())
                else:
                    action_key = int(action)
            except Exception:
                action_key = action
            self._debug_print(f"[DEBUG_ACTION] Model action: {action_names.get(action_key, 'UNKNOWN')} ({action})")

            # If you have an executed_action variable, log it here (otherwise comment out)
            # try:
            #     if isinstance(executed_action, (tuple, list, np.ndarray)):
            #         executed_action_key = int(executed_action[0])
            #     elif hasattr(executed_action, 'item'):
            #         executed_action_key = int(executed_action.item())
            #     else:
            #         executed_action_key = int(executed_action)
            # except Exception:
            #     executed_action_key = executed_action
            # self._debug_print(f"[DEBUG_ACTION] Executing action: {action_names.get(executed_action_key, 'UNKNOWN')} ({executed_action})")

            self._debug_print(f"[DEBUG_ACTION] Valid actions: {[action_names.get(a, '?') for a in valid_actions_before]}")

        # Calculate reward
        reward = self._calculate_reward(action_type, current_row)
        
        # Get the next observation (which includes action mask)
        obs = self.get_obs()
        
        # Check if episode is done
        done = self.current_step >= len(self.df) - 1
        
        # Log the step results
        if self.debug:
            self._debug_print(f"[DEBUG_STEP] Step: {self.current_step}, "
                            f"Action: {action_names.get(action_type, 'UNKNOWN')}, "
                            f"Reward: {reward:.4f}, "
                            f"Done: {done}")
            self._debug_print(f"[DEBUG_STEP] Balance: ${self.balance:.2f}, "
                            f"Shares: {self.shares}, "
                            f"Position Open: {self.position_open}")
        
        # Return the standard RLlib step return: obs, reward, done, truncated, info
        return obs, float(reward), done, False, {}

    def reset(self, *, seed=None, options=None):
        if self.debug:
            self._debug_print("\n=== Environment Reset ===")
            
        # Reset environment state
        self.current_step = 0
        self.balance = self.initial_balance
        self.net_worth = self.initial_balance
        self.max_net_worth = self.initial_balance
        self.shares = 0
        self.buy_price = 0
        self.buy_step = None
        self.position_open = False
        self.stoploss_price = None
        self.stoploss_distance = None
        self.total_reward = 0
        self.round_trip_trades = 0
        
        # Reset the DataFrame index to ensure proper iteration
        if self.df is not None:
            self.df = self.df.reset_index(drop=True)
        
        # Call parent class reset for seed handling
        super().reset(seed=seed)
        
        # Get the initial observation (which includes action mask)
        obs = self.get_obs()
        
        # Log the reset action
        if self.debug:
            self._debug_print(f"Initial balance: ${self.balance:.2f}")
            self._debug_print(f"Initial position: {'OPEN' if self.position_open else 'CLOSED'}")
            if self.position_open:
                self._debug_print(f"Buy price: ${self.buy_price:.2f}")
            self._debug_print(f"Current step: {self.current_step}")
            self._debug_print("=" * 40 + "\n")
            
            # Log the first observation
            if self.current_step < len(self.df):
                current_row = self.df.iloc[self.current_step]
                self._debug_print(f"First observation at: {current_row['datetime']}")
                self._debug_print(f"Open: {current_row['open']}, High: {current_row['high']}, "
                                 f"Low: {current_row['low']}, Close: {current_row['close']}, "
                                 f"Volume: {current_row['volume']}")
            
            # Log the action mask
            action_mask = obs['action_mask']
            action_names = ['HOLD', 'BUY', 'SELL']
            valid_actions = [action_names[i] for i, valid in enumerate(action_mask) if valid]
            self._debug_print(f"Valid actions: {valid_actions}")

        return obs, {}
