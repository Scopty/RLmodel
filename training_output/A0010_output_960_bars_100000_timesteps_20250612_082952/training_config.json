{
    "max_steps": 960,
    "total_timesteps": 100000,
    "start_time": "2025-06-12 08:29:52",
    "end_time": "2025-06-12 12:25:56",
    "model_architecture": "MaskableActorCriticPolicy(\n  (features_extractor): FlattenExtractor(\n    (flatten): Flatten(start_dim=1, end_dim=-1)\n  )\n  (pi_features_extractor): FlattenExtractor(\n    (flatten): Flatten(start_dim=1, end_dim=-1)\n  )\n  (vf_features_extractor): FlattenExtractor(\n    (flatten): Flatten(start_dim=1, end_dim=-1)\n  )\n  (mlp_extractor): MlpExtractor(\n    (policy_net): Sequential(\n      (0): Linear(in_features=13, out_features=512, bias=True)\n      (1): Tanh()\n      (2): Linear(in_features=512, out_features=512, bias=True)\n      (3): Tanh()\n      (4): Linear(in_features=512, out_features=256, bias=True)\n      (5): Tanh()\n    )\n    (value_net): Sequential(\n      (0): Linear(in_features=13, out_features=512, bias=True)\n      (1): Tanh()\n      (2): Linear(in_features=512, out_features=512, bias=True)\n      (3): Tanh()\n      (4): Linear(in_features=512, out_features=256, bias=True)\n      (5): Tanh()\n    )\n  )\n  (action_net): Linear(in_features=256, out_features=3, bias=True)\n  (value_net): Linear(in_features=256, out_features=1, bias=True)\n)",
    "env_parameters": "{}"
}