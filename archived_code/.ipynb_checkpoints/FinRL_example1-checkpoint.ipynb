{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e2b753-1d4c-4841-9084-2f78fb348282",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import matplotlib.pyplot as plt\n",
    "from stable_baselines3 import PPO, A2C, DDPG, SAC, TD3\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "# List of stocks in the Dow Jones 30\n",
    "tickers = [\n",
    "    'MMM', 'AXP', 'AAPL', 'BA', 'CAT', 'CVX', 'CSCO', 'KO', 'DIS', 'DOW',\n",
    "    'GS', 'HD', 'IBM', 'INTC', 'JNJ', 'JPM', 'MCD', 'MRK', 'MSFT', 'NKE',\n",
    "    'PFE', 'PG', 'TRV', 'UNH', 'UTX', 'VZ', 'V', 'WBA', 'WMT', 'XOM'\n",
    "]\n",
    "tickers.remove('DOW')\n",
    "tickers.remove('UTX')\n",
    "\n",
    "# Get historical data from Yahoo Finance and save it to dictionary\n",
    "def fetch_stock_data(tickers, start_date, end_date):\n",
    "    stock_data = {}\n",
    "    for ticker in tickers:\n",
    "        stock_data[ticker] = yf.download(ticker, start=start_date, end=end_date)\n",
    "    return stock_data\n",
    "\n",
    "# Call the function to get data\n",
    "stock_data = fetch_stock_data(tickers, '2009-01-01', '2020-05-08')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fc09a5-91ab-49d3-a7a5-b22f54a19a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training, validation and test sets\n",
    "training_data_time_range = ('2009-01-01', '2015-12-31')\n",
    "validation_data_time_range = ('2016-01-01', '2016-12-31')\n",
    "test_data_time_range = ('2017-01-01', '2020-05-08')\n",
    "\n",
    "# split the data into training, validation and test sets\n",
    "training_data = {}\n",
    "validation_data = {}\n",
    "test_data = {}\n",
    "\n",
    "for ticker, df in stock_data.items():\n",
    "    training_data[ticker] = df.loc[training_data_time_range[0]:training_data_time_range[1]]\n",
    "    validation_data[ticker] = df.loc[validation_data_time_range[0]:validation_data_time_range[1]]\n",
    "    test_data[ticker] = df.loc[test_data_time_range[0]:test_data_time_range[1]]\n",
    "\n",
    "# print shape of training, validation and test data\n",
    "ticker = 'AAPL'\n",
    "print(f'- Training data shape for {ticker}: {training_data[ticker].shape}')\n",
    "print(f'- Validation data shape for {ticker}: {validation_data[ticker].shape}')\n",
    "print(f'- Test data shape for {ticker}: {test_data[ticker].shape}\\n')\n",
    "\n",
    "# Display the first 5 rows of the data\n",
    "display(stock_data['AAPL'].head())\n",
    "print('\\n')\n",
    "\n",
    "# Plot:\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(training_data[ticker].index, training_data[ticker]['Open'], label='Training', color='blue')\n",
    "plt.plot(validation_data[ticker].index, validation_data[ticker]['Open'], label='Validation', color='red')\n",
    "plt.plot(test_data[ticker].index, test_data[ticker]['Open'], label='Test', color='green')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Value')\n",
    "plt.title(f'{ticker} Stock, Open Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0eafca7-f62a-41e0-ac51-89e94d26011f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_technical_indicators(df):\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    # Calculate EMA 12 and 26 for MACD\n",
    "    df.loc[:, 'EMA12'] = df['Close'].ewm(span=12, adjust=False).mean()\n",
    "    df.loc[:, 'EMA26'] = df['Close'].ewm(span=26, adjust=False).mean()\n",
    "    df.loc[:, 'MACD'] = df['EMA12'] - df['EMA26']\n",
    "    df.loc[:, 'Signal'] = df['MACD'].ewm(span=9, adjust=False).mean()\n",
    "\n",
    "    # Calculate RSI 14\n",
    "    rsi_14_mode = True\n",
    "    delta = df['Close'].diff()\n",
    "    if rsi_14_mode:\n",
    "        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()\n",
    "        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()\n",
    "        rs = gain / loss\n",
    "    else:\n",
    "        up = delta.where(delta > 0, 0)\n",
    "        down = -delta.where(delta < 0, 0)\n",
    "        rs = up.rolling(window=14).mean() / down.rolling(window=14).mean()\n",
    "    df.loc[:, 'RSI'] = 100 - (100 / (1 + rs))\n",
    "\n",
    "    # Calculate CCI 20\n",
    "    tp = (df['High'] + df['Low'] + df['Close']) / 3\n",
    "    sma_tp = tp.rolling(window=20).mean()\n",
    "    mean_dev = tp.rolling(window=20).apply(lambda x: np.mean(np.abs(x - x.mean())))\n",
    "    df.loc[:, 'CCI'] = (tp - sma_tp) / (0.015 * mean_dev)\n",
    "\n",
    "    # Calculate ADX 14\n",
    "    high_diff = df['High'].diff()\n",
    "    low_diff = df['Low'].diff()\n",
    "    df.loc[:, '+DM'] = np.where((high_diff > low_diff) & (high_diff > 0), high_diff, 0)\n",
    "    df.loc[:, '-DM'] = np.where((low_diff > high_diff) & (low_diff > 0), low_diff, 0)\n",
    "    tr = pd.concat([df['High'] - df['Low'], np.abs(df['High'] - df['Close'].shift(1)), np.abs(df['Low'] - df['Close'].shift(1))], axis=1).max(axis=1)\n",
    "    atr = tr.ewm(span=14, adjust=False).mean()\n",
    "    df.loc[:, '+DI'] = 100 * (df['+DM'].ewm(span=14, adjust=False).mean() / atr)\n",
    "    df.loc[:, '-DI'] = 100 * (df['-DM'].ewm(span=14, adjust=False).mean() / atr)\n",
    "    dx = 100 * np.abs(df['+DI'] - df['-DI']) / (df['+DI'] + df['-DI'])\n",
    "    df.loc[:, 'ADX'] = dx.ewm(span=14, adjust=False).mean()\n",
    "\n",
    "    # Drop NaN values\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    # Keep only the required columns\n",
    "    df = df[['Open', 'High', 'Low', 'Close', 'Volume', 'MACD', 'Signal', 'RSI', 'CCI', 'ADX']]\n",
    "\n",
    "    return df\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# add technical indicators to the training data for each stock\n",
    "for ticker, df in training_data.items():\n",
    "    training_data[ticker] = add_technical_indicators(df)\n",
    "\n",
    "# add technical indicators to the validation data for each stock\n",
    "for ticker, df in validation_data.items():\n",
    "    validation_data[ticker] = add_technical_indicators(df)\n",
    "\n",
    "# add technical indicators to the test data for each stock\n",
    "for ticker, df in test_data.items():\n",
    "    test_data[ticker] = add_technical_indicators(df)\n",
    "\n",
    "# print the first 5 rows of the data\n",
    "print(f'- Training data shape for {ticker}: {training_data[ticker].shape}')\n",
    "print(f'- Validation data shape for {ticker}: {validation_data[ticker].shape}')\n",
    "print(f'- Test data shape for {ticker}: {test_data[ticker].shape}\\n')\n",
    "\n",
    "display(test_data[ticker].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3b662a-a80a-45c2-bdf6-9d3c3091a2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = False\n",
    "\n",
    "class StockTradingEnv(gym.Env):\n",
    "\n",
    "    metadata = {'render_modes': ['human']}\n",
    "\n",
    "    # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "\n",
    "    def __init__(self, stock_data, transaction_cost_percent=0.005):\n",
    "        super(StockTradingEnv, self).__init__()\n",
    "        \"\"\"\n",
    "        This function initializes the environment with stock data and sets up necessary variables:\n",
    "        - Action and Observation Space: Defines the action space (buy/sell/hold) and\n",
    "                                        observation space (stock prices, balance, shares held, net worth, etc.).\n",
    "        - Account Variables: Initializes balance, net worth, shares held, and transaction costs.\n",
    "        \"\"\"\n",
    "\n",
    "        # Remove any empty DataFrames\n",
    "        self.stock_data = {ticker: df for ticker, df in stock_data.items() if not df.empty}\n",
    "        self.tickers = list(self.stock_data.keys())\n",
    "\n",
    "        print('self.tickers', self.tickers)\n",
    "        \n",
    "        if not self.tickers:\n",
    "            raise ValueError(\"All provided stock data is empty\")\n",
    "\n",
    "        # Calculate the size of one stock's data\n",
    "        sample_df = next(iter(self.stock_data.values()))\n",
    "        self.n_features = len(sample_df.columns)\n",
    "        \n",
    "        # Define action and observation space\n",
    "        self.action_space = spaces.Box(low=-1, high=1, shape=(len(self.tickers),), dtype=np.float32)\n",
    "\n",
    "        print('self.action_space', self.action_space)\n",
    "\n",
    "        # Observation space: price data for each stock + balance + shares held + net worth + max net worth + current step\n",
    "        self.obs_shape = self.n_features * len(self.tickers) + 2 + len(self.tickers) + 2\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(self.obs_shape,), dtype=np.float32)\n",
    "\n",
    "        print('self.obs_shape', self.obs_shape)\n",
    "        print('self.observation_space', self.observation_space)\n",
    "\n",
    "        \n",
    "        # Initialize account balance\n",
    "\n",
    "        self.initial_balance = 1000\n",
    "        self.balance = float(self.initial_balance)  # Ensure balance is a scalar\n",
    "        \n",
    "        self.initial_balance = 1000\n",
    "        self.balance = self.initial_balance\n",
    "        self.net_worth = self.initial_balance\n",
    "        self.max_net_worth = self.initial_balance\n",
    "        self.shares_held = {ticker: 0 for ticker in self.tickers}\n",
    "        self.total_shares_sold = {ticker: 0 for ticker in self.tickers}\n",
    "        self.total_sales_value = {ticker: 0 for ticker in self.tickers}\n",
    "\n",
    "        # Set the current step\n",
    "        self.current_step = 0\n",
    "\n",
    "        # Calculate the minimum length of data across all stocks\n",
    "        self.max_steps = max(0, min(len(df) for df in self.stock_data.values()) - 1)\n",
    "\n",
    "        # Transaction cost\n",
    "        self.transaction_cost_percent = transaction_cost_percent\n",
    "\n",
    "        # Short Strategy\n",
    "        self.short = False\n",
    "\n",
    "    # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        \"\"\" Resets the environment to its initial state for a new episode. \"\"\"\n",
    "\n",
    "        # Reset the account balance\n",
    "        self.balance = float(self.initial_balance)  # Ensure balance is a scalar\n",
    "        self.net_worth = self.initial_balance\n",
    "        self.max_net_worth = self.initial_balance\n",
    "        self.shares_held = {ticker: 0 for ticker in self.tickers}\n",
    "        self.total_shares_sold = {ticker: 0 for ticker in self.tickers}\n",
    "        self.total_sales_value = {ticker: 0 for ticker in self.tickers}\n",
    "        self.current_step = 0\n",
    "        return self._next_observation(), {}\n",
    "\n",
    "    # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "\n",
    "    def _next_observation(self):\n",
    "        \"\"\" Returns the current state of the environment, including stock prices, balance, shares held, net worth, etc. \"\"\"\n",
    "\n",
    "        # initialize the frame\n",
    "        frame = np.zeros(self.obs_shape)\n",
    "\n",
    "        # Add stock data for each ticker\n",
    "        idx = 0\n",
    "        # Loop through each ticker\n",
    "        for ticker in self.tickers:\n",
    "            # Get the DataFrame for the current ticker\n",
    "            df = self.stock_data[ticker]\n",
    "            # If the current step is less than the length of the DataFrame, add the price data for the current step\n",
    "            if self.current_step < len(df):\n",
    "                frame[idx:idx+self.n_features] = df.iloc[self.current_step].values\n",
    "            # Otherwise, add the last price data available\n",
    "            elif len(df) > 0:\n",
    "                frame[idx:idx+self.n_features] = df.iloc[-1].values\n",
    "            # Move the index to the next ticker\n",
    "            idx += self.n_features\n",
    "\n",
    "        # Add balance, shares held, net worth, max net worth, and current step\n",
    "        frame[-4-len(self.tickers)] = self.balance # Balance\n",
    "        frame[-3-len(self.tickers):-3] = [self.shares_held[ticker] for ticker in self.tickers] # Shares held\n",
    "        frame[-3] = self.net_worth # Net worth\n",
    "        frame[-2] = self.max_net_worth # Max net worth\n",
    "        frame[-1] = self.current_step # Current step\n",
    "\n",
    "        print('frame:',frame)\n",
    "        \n",
    "        return frame\n",
    "\n",
    "    # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "\n",
    "    def step(self, actions):\n",
    "        \"\"\" Executes an action in the environment, updates the state, calculates rewards, and checks if the episode is done. \"\"\"\n",
    "\n",
    "        # Update the current step\n",
    "        self.current_step += 1\n",
    "\n",
    "        # Check if we have reached the maximum number of steps\n",
    "        if self.current_step > self.max_steps:\n",
    "            return self._next_observation(), 0, True, False, {}\n",
    "\n",
    "        close_prices = {}\n",
    "\n",
    "        if debug: print('tickerlist', self.tickers)\n",
    "        \n",
    "        # Loop through each ticker and perform the action\n",
    "        for i, ticker in enumerate(self.tickers):\n",
    "            if debug: print('ticker', ticker, 'i', i)\n",
    "            \n",
    "            # Get the current open and close price of the stock\n",
    "            current_day = self.stock_data[ticker].iloc[self.current_step]\n",
    "            \n",
    "            open_price = current_day['Open'].iloc[0]  # Extract scalar value\n",
    "            close_price = current_day['Close'].iloc[0]  # Extract scalar value\n",
    "\n",
    "            if debug: print(f\"Open Price: {open_price}, Type: {type(open_price)}\")\n",
    "            if debug: print(f\"Close Price: {close_price}, Type: {type(close_price)}\")\n",
    "\n",
    "            # Check for NaN values in stock prices\n",
    "            if np.isnan(open_price) or np.isnan(close_price):\n",
    "                raise ValueError(f\"NaN value detected in stock prices for ticker {ticker} at step {self.current_step}\")\n",
    "            \n",
    "            # Record the close price\n",
    "            close_prices[ticker] = close_price\n",
    "\n",
    "            # Get the action for the current ticker\n",
    "            action = actions[i]\n",
    "\n",
    "            if debug: print(f\"Action: {action}, Type: {type(action)}\")\n",
    "\n",
    "            action_price = open_price if self.short else close_price\n",
    "\n",
    "            if action > 0:  # Buy\n",
    "                \n",
    "                    # Ensure self.balance is a scalar\n",
    "                if isinstance(self.balance, (int, float)):\n",
    "                    balance_scalar = self.balance\n",
    "                elif isinstance(self.balance, list):  # Handle regular Python lists\n",
    "                    balance_scalar = self.balance[0]\n",
    "                elif hasattr(self.balance, 'iloc'):  # Handle pandas Series/DataFrame\n",
    "                    balance_scalar = self.balance.iloc[0]\n",
    "                else:\n",
    "                    raise TypeError(\"self.balance must be an integer, list, or pandas Series\")\n",
    "    \n",
    "                # Ensure action and action_price are scalars\n",
    "                action_scalar = action if isinstance(action, (int, float, np.float32)) else action.iloc[0]\n",
    "    \n",
    "                if debug: print(balance_scalar)\n",
    "                if debug: print(action_scalar)\n",
    "                if debug: print(action_price)\n",
    "    \n",
    "                # Calculate the number of shares to buy\n",
    "                shares_to_buy = int(balance_scalar * action_scalar / action_price)\n",
    "    \n",
    "                if debug: print('shares_to_buy', shares_to_buy)\n",
    "    \n",
    "                # Calculate the cost of the shares\n",
    "                cost = shares_to_buy * action_price\n",
    "    \n",
    "                if debug: print('cost', cost)\n",
    "    \n",
    "                # Transaction cost\n",
    "                transaction_cost = cost * self.transaction_cost_percent\n",
    "    \n",
    "                if debug: print('transaction_cost', transaction_cost)\n",
    "\n",
    "                if debug: print(f\"Before Update - self.balance: {self.balance}, Type: {type(self.balance)}\")\n",
    "                if debug: print(f\"cost: {cost}, Type: {type(cost)}\")\n",
    "                if debug: print(f\"transaction_cost: {transaction_cost}, Type: {type(transaction_cost)}\")\n",
    "    \n",
    "                # Update the balance as a scalar\n",
    "                self.balance = float(balance_scalar - (cost + transaction_cost))\n",
    "                if debug: print(f\"After Update - self.balance: {self.balance}, Type: {type(self.balance)}\")\n",
    "                if debug: print('self.balance', self.balance)\n",
    "    \n",
    "                # Update the total shares held\n",
    "                self.shares_held[ticker] += shares_to_buy\n",
    "            elif action < 0:  # Sell\n",
    "                # Calculate the number of shares to sell\n",
    "                shares_to_sell = int(self.shares_held[ticker] * abs(action))\n",
    "                # Calculate the sale value\n",
    "                sale = shares_to_sell * action_price\n",
    "                # Transaction cost\n",
    "                transaction_cost = sale * self.transaction_cost_percent\n",
    "                # Update the balance and shares held\n",
    "                self.balance += (sale - transaction_cost)\n",
    "                # Update the total shares sold\n",
    "                self.shares_held[ticker] -= shares_to_sell\n",
    "                # Update the shares sold\n",
    "                self.total_shares_sold[ticker] += shares_to_sell\n",
    "                # Update the total sales value\n",
    "                self.total_sales_value[ticker] += sale\n",
    "\n",
    "        # Calculate the net worth\n",
    "        self.net_worth = self.balance + sum(self.shares_held[ticker] * close_prices[ticker] for ticker in self.tickers)\n",
    "  \n",
    "        # Update the max net worth\n",
    "        self.max_net_worth = max(self.net_worth, self.max_net_worth)\n",
    "\n",
    "        # Calculate the reward\n",
    "        reward = self.net_worth - self.initial_balance\n",
    "\n",
    "        # Check if the episode is done\n",
    "        done = self.net_worth <= 0 or self.current_step >= self.max_steps\n",
    "\n",
    "        obs = self._next_observation()\n",
    "\n",
    "        return obs, reward, done, False, {}\n",
    "\n",
    "    # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        \"\"\" Displays the current state of the environment in a human-readable format. \"\"\"\n",
    "\n",
    "        # Print the current step, balance, shares held, net worth, and profit\n",
    "        profit = self.net_worth - self.initial_balance\n",
    "        print(f'Step: {self.current_step}')\n",
    "        print(f'Balance: {self.balance:.2f}')\n",
    "        for ticker in self.tickers:\n",
    "            print(f'{ticker} Shares held: {self.shares_held[ticker]}')\n",
    "        print(f'Net worth: {self.net_worth:.2f}')\n",
    "        print(f'Profit: {profit:.2f}')\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\" Placeholder for any cleanup operations \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1810f6-2d26-4f3a-84f0-a736056b53fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyGradientLossCallback(BaseCallback):\n",
    "    \"\"\"\n",
    "    A custom callback class that logs the policy_gradient_loss during training.\n",
    "    This class extends BaseCallback and used to capture and store the metrics we want.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, verbose=0):\n",
    "        super(PolicyGradientLossCallback, self).__init__(verbose)\n",
    "        self.losses = []\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        if hasattr(self.model, 'logger'):\n",
    "            logs = self.model.logger.name_to_value\n",
    "            if 'train/policy_gradient_loss' in logs:\n",
    "                loss = logs['train/policy_gradient_loss']\n",
    "                self.losses.append(loss)\n",
    "        return True\n",
    "\n",
    "    def _on_training_end(self):\n",
    "        \"\"\" Plot the loss after training ends \"\"\"\n",
    "        name = self.model.__class__.__name__\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.plot(self.losses, label='Policy Gradient Loss')\n",
    "        plt.title(f'{name} - Policy Gradient Loss During Training')\n",
    "        plt.xlabel('Training Steps')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eda44b2-157a-44ac-a366-dbbd899cb6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define PPO Agent\n",
    "class PPOAgent:\n",
    "\n",
    "    def __init__(self, env, total_timesteps, threshold):\n",
    "        self.model = PPO(\"MlpPolicy\", env, verbose=1)\n",
    "        self.callback = PolicyGradientLossCallback()\n",
    "        self.model.learn(total_timesteps=total_timesteps, callback=self.callback)\n",
    "        self.threshold = threshold\n",
    "\n",
    "    # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "\n",
    "    def predict(self, obs):\n",
    "        action, _ = self.model.predict(obs, deterministic=True)\n",
    "        return action\n",
    "\n",
    "    # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "\n",
    "    def action_to_recommendation(self, action):\n",
    "        recommendations = []\n",
    "        for a in action:\n",
    "            if a > self.threshold:\n",
    "                recommendations.append('buy')\n",
    "            elif a < -self.threshold:\n",
    "                recommendations.append('sell')\n",
    "            else:\n",
    "                recommendations.append('hold')\n",
    "        return recommendations\n",
    "\n",
    "    # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "\n",
    "    def validate(self, env):\n",
    "        obs = env.reset()\n",
    "        total_rewards = 0\n",
    "        for _ in range(1000):  # Adjust based on needs\n",
    "            action, _ = self.model.predict(obs)\n",
    "            obs, reward, done, _ = env.step(action)\n",
    "            total_rewards += reward\n",
    "            if done:\n",
    "                obs = env.reset()\n",
    "        print(f'Agent Validation Reward: {total_rewards}')\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Define A2C Agent\n",
    "class A2CAgent(PPOAgent):\n",
    "    def __init__(self, env, total_timesteps, threshold):\n",
    "        super().__init__(env, total_timesteps, threshold)\n",
    "        self.model = A2C(\"MlpPolicy\", env, verbose=1)\n",
    "        self.callback = PolicyGradientLossCallback()\n",
    "        self.model.learn(total_timesteps=total_timesteps, callback=self.callback)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Define DDPG Agent\n",
    "class DDPGAgent(PPOAgent):\n",
    "    def __init__(self, env, total_timesteps, threshold):\n",
    "        super().__init__(env, total_timesteps, threshold)\n",
    "        self.model = DDPG(\"MlpPolicy\", env, verbose=1)\n",
    "        self.callback = PolicyGradientLossCallback()\n",
    "        self.model.learn(total_timesteps=total_timesteps, callback=self.callback)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Define SAC Agent\n",
    "class SACAgent(PPOAgent):\n",
    "    def __init__(self, env, total_timesteps, threshold):\n",
    "        super().__init__(env, total_timesteps, threshold)\n",
    "        self.model = SAC(\"MlpPolicy\", env, verbose=1)\n",
    "        self.callback = PolicyGradientLossCallback()\n",
    "        self.model.learn(total_timesteps=total_timesteps, callback=self.callback)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Define TD3 Agent\n",
    "class TD3Agent(PPOAgent):\n",
    "    def __init__(self, env, total_timesteps, threshold):\n",
    "        super().__init__(env, total_timesteps, threshold)\n",
    "        self.model = TD3(\"MlpPolicy\", env, verbose=1)\n",
    "        self.callback = PolicyGradientLossCallback()\n",
    "        self.model.learn(total_timesteps=total_timesteps, callback=self.callback)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Define Ensemble Agent\n",
    "class EnsembleAgent:\n",
    "\n",
    "    def __init__(self, ppo_model, a2c_model, ddpg_model, sac_model, td3_model, threshold):\n",
    "        self.ppo_model = ppo_model\n",
    "        self.a2c_model = a2c_model\n",
    "        self.ddpg_model = ddpg_model\n",
    "        self.sac_model = sac_model\n",
    "        self.td3_model = td3_model\n",
    "        self.threshold = threshold\n",
    "\n",
    "    # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "\n",
    "    def predict(self, obs):\n",
    "        ppo_action, _ = self.ppo_model.predict(obs, deterministic=True)\n",
    "        a2c_action, _ = self.a2c_model.predict(obs, deterministic=True)\n",
    "        ddpg_action, _ = self.ddpg_model.predict(obs, deterministic=True)\n",
    "        sac_action, _ = self.sac_model.predict(obs, deterministic=True)\n",
    "        td3_action, _ = self.td3_model.predict(obs, deterministic=True)\n",
    "\n",
    "        # Average the actions\n",
    "        ensemble_action = np.mean([ppo_action, a2c_action, ddpg_action, sac_action, td3_action], axis=0)\n",
    "        return ensemble_action\n",
    "\n",
    "    # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "\n",
    "    def action_to_recommendation(self, action):\n",
    "        recommendations = []\n",
    "        for a in action:\n",
    "            if a > self.threshold:\n",
    "                recommendations.append('buy')\n",
    "            elif a < -self.threshold:\n",
    "                recommendations.append('sell')\n",
    "            else:\n",
    "                recommendations.append('hold')\n",
    "        return recommendations\n",
    "\n",
    "    # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "\n",
    "    def validate(self, env):\n",
    "        obs = env.reset()\n",
    "        total_rewards = 0\n",
    "        for _ in range(1000):  # Adjust based on needs\n",
    "            action = self.predict(obs)\n",
    "            obs, reward, done, _ = env.step(action)\n",
    "            total_rewards += reward\n",
    "            if done:\n",
    "                obs = env.reset()\n",
    "        print(f'Agent Validation Reward: {total_rewards}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c38d5b-c32b-427e-b7c6-c223dcb25e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create the environment and train the agents\n",
    "def create_env_and_train_agents(train_data, val_data, total_timesteps, threshold):\n",
    "\n",
    "    # Create environments for training and validation\n",
    "    train_env = DummyVecEnv([lambda: StockTradingEnv(train_data)])\n",
    "    val_env = DummyVecEnv([lambda: StockTradingEnv(val_data)])\n",
    "\n",
    "    # Train and Validate PPO Agent\n",
    "    ppo_agent = PPOAgent(train_env, total_timesteps, threshold)\n",
    "    ppo_agent.validate(val_env)\n",
    "    \n",
    "    # Train and Validate A2C Agent\n",
    "    #a2c_agent = A2CAgent(train_env, total_timesteps, threshold)\n",
    "    #a2c_agent.validate(val_env)\n",
    "\n",
    "    # Train and Validate DDPG Agent\n",
    "    #ddpg_agent = DDPGAgent(train_env, total_timesteps, threshold)\n",
    "    #ddpg_agent.validate(val_env)\n",
    "\n",
    "    # Train and Validate SAC Agent\n",
    "    #sac_agent = SACAgent(train_env, total_timesteps, threshold)\n",
    "    #sac_agent.validate(val_env)\n",
    "\n",
    "    # Train and Validate TD3 Agent\n",
    "    #td3_agent = TD3Agent(train_env, total_timesteps, threshold)\n",
    "    #td3_agent.validate(val_env)\n",
    "\n",
    "    # Train and Validate the ensemble agent\n",
    "    #ensemble_agent = EnsembleAgent(ppo_agent.model, a2c_agent.model, ddpg_agent.model,\n",
    "    #                              sac_agent.model, td3_agent.model, threshold)\n",
    "    #ensemble_agent.validate(val_env)\n",
    "\n",
    "    #return train_env, val_env, ppo_agent, a2c_agent, ddpg_agent, sac_agent, td3_agent, ensemble_agent\n",
    "    \n",
    "    return train_env, val_env, ppo_agent\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Function to visualize portfolio changes\n",
    "def visualize_portfolio(steps, balances, net_worths, shares_held, tickers,\n",
    "                        show_balance=True, show_net_worth=True, show_shares_held=True):\n",
    "\n",
    "    fig, axs = plt.subplots(3, figsize=(12, 18))\n",
    "\n",
    "    # Plot the balance\n",
    "    if show_balance:\n",
    "        axs[0].plot(steps, balances, label='Balance')\n",
    "        axs[0].set_title('Balance Over Time')\n",
    "        axs[0].set_xlabel('Steps')\n",
    "        axs[0].set_ylabel('Balance')\n",
    "        axs[0].legend()\n",
    "\n",
    "    # Plot the net worth\n",
    "    if show_net_worth:\n",
    "        axs[1].plot(steps, net_worths, label='Net Worth', color='orange')\n",
    "        axs[1].set_title('Net Worth Over Time')\n",
    "        axs[1].set_xlabel('Steps')\n",
    "        axs[1].set_ylabel('Net Worth')\n",
    "        axs[1].legend()\n",
    "\n",
    "    # Plot the shares held\n",
    "    if show_shares_held:\n",
    "        for ticker in tickers:\n",
    "            axs[2].plot(steps, shares_held[ticker], label=f'Shares Held: {ticker}')\n",
    "        axs[2].set_title('Shares Held Over Time')\n",
    "        axs[2].set_xlabel('Steps')\n",
    "        axs[2].set_ylabel('Shares Held')\n",
    "        axs[2].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# function to visualize the portfolio net worth\n",
    "def visualize_portfolio_net_worth(steps, net_worths):\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(steps, net_worths, label='Net Worth', color='orange')\n",
    "    plt.title('Net Worth Over Time')\n",
    "    plt.xlabel('Steps')\n",
    "    plt.ylabel('Net Worth')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# function to visualize the multiple portfolio net worths ( same chart )\n",
    "def visualize_multiple_portfolio_net_worth(steps, net_worths_list, labels):\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for i, net_worths in enumerate(net_worths_list):\n",
    "        plt.plot(steps, net_worths, label=labels[i])\n",
    "    plt.title('Net Worth Over Time')\n",
    "    plt.xlabel('Steps')\n",
    "    plt.ylabel('Net Worth')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def test_agent(env, agent, stock_data, n_tests=1000, visualize=False):\n",
    "    \"\"\" Test a single agent and track performance metrics, with an option to visualize the results \"\"\"\n",
    "\n",
    "    # Initialize metrics tracking\n",
    "    metrics = {\n",
    "        'steps': [],\n",
    "        'balances': [],\n",
    "        'net_worths': [],\n",
    "        'shares_held': {ticker: [] for ticker in stock_data.keys()}\n",
    "    }\n",
    "\n",
    "    # Reset the environment before starting the tests\n",
    "    obs = env.reset()\n",
    "\n",
    "    for i in range(n_tests):\n",
    "\n",
    "        metrics['steps'].append(i)\n",
    "\n",
    "        action = agent.predict(obs)\n",
    "\n",
    "        obs, rewards, dones, infos = env.step(action)\n",
    "\n",
    "        if visualize:\n",
    "            env.render()\n",
    "\n",
    "        # Track metrics\n",
    "        metrics['balances'].append(env.get_attr('balance')[0])\n",
    "        metrics['net_worths'].append(env.get_attr('net_worth')[0])\n",
    "        env_shares_held = env.get_attr('shares_held')[0]\n",
    "\n",
    "        # Update shares held for each ticker\n",
    "        for ticker in stock_data.keys():\n",
    "            if ticker in env_shares_held:\n",
    "                metrics['shares_held'][ticker].append(env_shares_held[ticker])\n",
    "            else:\n",
    "                metrics['shares_held'][ticker].append(0)  # Append 0 if ticker is not found\n",
    "\n",
    "        if dones:\n",
    "            obs = env.reset()\n",
    "\n",
    "    return metrics\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def test_and_visualize_agents(env, agents, data, n_tests=1000):\n",
    "\n",
    "    metrics = {}\n",
    "    for agent_name, agent in agents.items():\n",
    "        print(f\"Testing {agent_name}...\")\n",
    "        metrics[agent_name] = test_agent(env, agent, data, n_tests=n_tests, visualize=True)\n",
    "\n",
    "    # Extract net worths for visualization\n",
    "    net_worths = [metrics[agent_name]['net_worths'] for agent_name in agents.keys()]\n",
    "    steps = next(iter(metrics.values()))['steps']  # Assuming all agents have the same step count for simplicity\n",
    "\n",
    "    # Visualize the performance metrics of multiple agents\n",
    "    visualize_multiple_portfolio_net_worth(steps, net_worths, list(agents.keys()))\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def compare_and_plot_agents(agents_metrics, labels, risk_free_rate=0.0):\n",
    "\n",
    "    # Function to compare returns, standard deviation, and sharpe ratio of agents\n",
    "    def compare_agents(agents_metrics, labels):\n",
    "        returns = []\n",
    "        stds = []\n",
    "        sharpe_ratios = []\n",
    "\n",
    "        for metrics in agents_metrics:\n",
    "\n",
    "            net_worths = metrics['net_worths']\n",
    "\n",
    "            # Calculate daily returns\n",
    "            daily_returns = np.diff(net_worths) / net_worths[:-1]\n",
    "            avg_return = np.mean(daily_returns)\n",
    "            std_return = np.std(daily_returns)\n",
    "            sharpe_ratio = ((avg_return - risk_free_rate) / std_return) if std_return != 0 else 'Inf'\n",
    "\n",
    "            returns.append(avg_return)\n",
    "            stds.append(std_return)\n",
    "            sharpe_ratios.append(sharpe_ratio)\n",
    "\n",
    "        df = pd.DataFrame({\n",
    "            'Agent': labels,\n",
    "            'Return': returns,\n",
    "            'Standard Deviation': stds,\n",
    "            'Sharpe Ratio': sharpe_ratios\n",
    "        })\n",
    "\n",
    "        return df\n",
    "\n",
    "    # Compare agents\n",
    "    df = compare_agents(agents_metrics, labels)\n",
    "\n",
    "    # Sort the dataframe by sharpe ratio\n",
    "    df_sorted = df.sort_values(by='Sharpe Ratio', ascending=False)\n",
    "\n",
    "    # Display the dataframe\n",
    "    display(df_sorted)\n",
    "\n",
    "    # Plot bar chart for sharpe ratio\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(df_sorted['Agent'], df_sorted['Sharpe Ratio'])\n",
    "    plt.title('Sharpe Ratio Comparison')\n",
    "    plt.xlabel('Agent')\n",
    "    plt.ylabel('Sharpe Ratio')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329ed4d4-2334-43fd-aba9-cbcc276c189f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the environment and train the agents\n",
    "threshold = 0.1\n",
    "total_timesteps = 100\n",
    "#train_env, val_env, ppo_agent, a2c_agent, ddpg_agent, sac_agent, td3_agent, ensemble_agent = \\\n",
    "#  create_env_and_train_agents(training_data, validation_data, total_timesteps, threshold)\n",
    "\n",
    "train_env, val_env, ppo_agent = create_env_and_train_agents(training_data, validation_data, total_timesteps, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3007af14-74de-4a52-9473-9b9169ca57b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tests = 1000\n",
    "agents = {\n",
    "    'PPO Agent': ppo_agent,\n",
    "    #'A2C Agent': a2c_agent,\n",
    "    #'DDPG Agent': ddpg_agent,\n",
    "    #'SAC Agent': sac_agent,\n",
    "    #'TD3 Agent': td3_agent,\n",
    "    #'Ensemble Agent': ensemble_agent\n",
    "}\n",
    "\n",
    "test_and_visualize_agents(train_env, agents, training_data, n_tests=n_tests)\n",
    "\n",
    "test_env = DummyVecEnv([lambda: StockTradingEnv(test_data)])\n",
    "test_and_visualize_agents(test_env, agents, test_data, n_tests=n_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229aa06c-a655-433d-8627-fcbe4e1bfc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_next_day_data(stock_data):\n",
    "    \"\"\" Prepares the observation for the next trading day \"\"\"\n",
    "\n",
    "    # Initialize the environment with the current stock data\n",
    "    env = StockTradingEnv(stock_data)\n",
    "    env.reset()\n",
    "\n",
    "    # Prepare the next day's observation\n",
    "    next_day_observations = env._next_observation()\n",
    "\n",
    "    return next_day_observations\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def generate_next_day_recommendations(agents, next_day_observation):\n",
    "    \"\"\" Generate recommendations for the next trading day using the trained agents \"\"\"\n",
    "\n",
    "    recommendations = {agent_name: [] for agent_name in agents.keys()}\n",
    "\n",
    "    for agent_name, agent in agents.items():\n",
    "        action = agent.predict(next_day_observation)\n",
    "        recs = agent.action_to_recommendation(action)\n",
    "        recommendations[agent_name] = zip(recs, action)\n",
    "\n",
    "    return recommendations\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# Prepare next day's observation\n",
    "next_day_observation = prepare_next_day_data(test_data)\n",
    "\n",
    "# Generate recommendations for the next trading day\n",
    "recommendations = generate_next_day_recommendations(agents, next_day_observation)\n",
    "\n",
    "# Print or display recommendations\n",
    "for agent_name, recs in recommendations.items():\n",
    "  if agent_name == 'Ensemble Agent':\n",
    "      print(f'\\nRecommendations for {agent_name}:')\n",
    "      for ticker, recommendation in zip(tickers, recs):\n",
    "          print(f\"{ticker}: {recommendation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6376e27-1690-4d85-9410-b984fade97f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter_env",
   "language": "python",
   "name": "jupyter_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
